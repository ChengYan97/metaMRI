{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import torch\n",
    "import learn2learn as l2l\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "# The corase reconstruction is the rss of the zerofilled multi-coil kspaces\n",
    "# after inverse FT.\n",
    "from functions.data.transforms import UnetDataTransform, UnetDataTransform_norm, normalize\n",
    "# Import a torch.utils.data.Dataset class that takes a list of data examples, a path to those examples\n",
    "# a data transform and outputs a torch dataset.\n",
    "from functions.data.mri_dataset import SliceDataset\n",
    "# Unet architecture as nn.Module\n",
    "from functions.models.unet import Unet\n",
    "# Function that returns a MaskFunc object either for generatig random or equispaced masks\n",
    "from functions.data.subsample import create_mask_for_mask_type\n",
    "# Implementation of SSIMLoss\n",
    "from functions.training.losses import SSIMLoss\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "\n",
    "experiment_name = 'E7.2_self(l1)_T8x200_100epoch'\n",
    "\n",
    "# tensorboard dir\n",
    "experiment_path = '/cheng/metaMRI/metaMRI/save/' + experiment_name + '/'\n",
    "writer = SummaryWriter(experiment_path)\n",
    "\n",
    "# seed\n",
    "SEED = 1\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# hyperparameter\n",
    "TRAINING_EPOCH = 120\n",
    "num_sample_train = 200\n",
    "num_sample_val = 100\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "# data path\n",
    "path_train1 = '/cheng/metaMRI/metaMRI/data_dict/E6.3/P/knee_train_PD_Aera_2-9.yaml'\n",
    "path_train2 = '/cheng/metaMRI/metaMRI/data_dict/E6.3/P/knee_train_PD_Aera_15-22.yaml'\n",
    "path_train3 = '/cheng/metaMRI/metaMRI/data_dict/E6.3/P/knee_train_PD_Biograph_15-22.yaml'\n",
    "path_train4 = '/cheng/metaMRI/metaMRI/data_dict/E6.3/P/knee_train_PD_Skyra_15-22.yaml'\n",
    "path_train5 = '/cheng/metaMRI/metaMRI/data_dict/E6.3/P/knee_train_PDFS_Aera_2-9.yaml'\n",
    "path_train6 = '/cheng/metaMRI/metaMRI/data_dict/E6.3/P/knee_train_PDFS_Aera_15-22.yaml'\n",
    "path_train7 = '/cheng/metaMRI/metaMRI/data_dict/E6.3/P/knee_train_PDFS_Biograph_15-22.yaml'\n",
    "path_train8 = '/cheng/metaMRI/metaMRI/data_dict/E6.3/P/knee_train_PDFS_Skyra_15-22.yaml'\n",
    "\n",
    "path_val1 = '/cheng/metaMRI/metaMRI/data_dict/E6.3/P/knee_val_PD_Aera_2-9.yaml'\n",
    "path_val2 = '/cheng/metaMRI/metaMRI/data_dict/E6.3/P/knee_val_PD_Aera_15-22.yaml'\n",
    "path_val3 = '/cheng/metaMRI/metaMRI/data_dict/E6.3/P/knee_val_PD_Biograph_15-22.yaml'\n",
    "path_val4 = '/cheng/metaMRI/metaMRI/data_dict/E6.3/P/knee_val_PD_Skyra_15-22.yaml'\n",
    "path_val5 = '/cheng/metaMRI/metaMRI/data_dict/E6.3/P/knee_val_PDFS_Aera_2-9.yaml'\n",
    "path_val6 = '/cheng/metaMRI/metaMRI/data_dict/E6.3/P/knee_val_PDFS_Aera_15-22.yaml'\n",
    "path_val7 = '/cheng/metaMRI/metaMRI/data_dict/E6.3/P/knee_val_PDFS_Biograph_15-22.yaml'\n",
    "path_val8 = '/cheng/metaMRI/metaMRI/data_dict/E6.3/P/knee_val_PDFS_Skyra_15-22.yaml'\n",
    "\n",
    "\n",
    "# mask function and data transform\n",
    "mask_function = create_mask_for_mask_type(mask_type_str = 'random', self_sup = False, \n",
    "                    center_fraction = 0.08, acceleration = 4.0, acceleration_total = 3.0)\n",
    "\n",
    "data_transform_train = UnetDataTransform_norm('multicoil', mask_func = mask_function, use_seed=False, mode='train')\n",
    "data_transform = UnetDataTransform_norm('multicoil', mask_func = mask_function, use_seed=True, mode='adapt')\n",
    "\n",
    "# training dataset and data loader\n",
    "path_train_list = [path_train1, path_train2, path_train3, path_train4, path_train5, path_train6, path_train7, path_train8]\n",
    "trainset_list = []\n",
    "for path in path_train_list:\n",
    "    trainset = SliceDataset(dataset = path, path_to_dataset='', path_to_sensmaps=None, provide_senmaps=False, \n",
    "                challenge=\"multicoil\", transform=data_transform_train, use_dataset_cache=True, num_samples= num_sample_train)\n",
    "    trainset_list.append(trainset)\n",
    "\n",
    "train_set = torch.utils.data.ConcatDataset(trainset_list)\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset = train_set, batch_size = BATCH_SIZE,\n",
    "                shuffle = True, generator = torch.Generator().manual_seed(1), pin_memory = True)\n",
    "print(\"Training date number: \", len(train_dataloader.dataset))\n",
    "\n",
    "# validation dataset and data loader\n",
    "path_val_list = [path_val1, path_val2, path_val3, path_val4, path_val5, path_val6, path_val7, path_val8]\n",
    "val_dataset_list = []\n",
    "for path_val in path_val_list:\n",
    "    valset = SliceDataset(dataset = path_val, path_to_dataset='', path_to_sensmaps=None, provide_senmaps=False, \n",
    "                challenge=\"multicoil\", transform=data_transform, use_dataset_cache=True, num_samples= num_sample_val)\n",
    "    val_dataset_list.append(valset)\n",
    "\n",
    "val_set = torch.utils.data.ConcatDataset(val_dataset_list)\n",
    "val_dataloader = torch.utils.data.DataLoader(dataset = val_set, batch_size = 1, \n",
    "                shuffle = False, generator = torch.Generator().manual_seed(1), pin_memory = False)\n",
    "print(\"Validation date number: \", len(val_dataloader.dataset))\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "def train(model, dataloader, optimizer): \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    l1_loss = torch.nn.L1Loss(reduction='sum')\n",
    "\n",
    "    for iter, batch in tqdm(enumerate(dataloader)):\n",
    "        input_image, target_image, mean, std, fname, slice_num = batch\n",
    "        train_inputs = input_image.to(device)\n",
    "        train_targets = target_image.to(device)\n",
    "        std = std.to(device)\n",
    "        mean = mean.to(device)\n",
    "\n",
    "        train_outputs = model(train_inputs)\n",
    "        train_outputs = train_outputs * std + mean\n",
    "\n",
    "        loss = l1_loss(train_outputs, train_targets) / torch.sum(torch.abs(train_targets))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(dataloader)\n",
    "    return avg_train_loss\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_l1_loss = 0.0\n",
    "    total_ssim_loss = 0.0\n",
    "    total_psnr_loss = 0.0\n",
    "    total_nmse_loss = 0.0\n",
    "    l1_loss = torch.nn.L1Loss(reduction='sum')\n",
    "    ssim_fct = SSIMLoss()\n",
    "    psner_mse_fct = torch.nn.MSELoss(reduction='mean')\n",
    "    mse_fct = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "    for iter, batch in enumerate(dataloader): \n",
    "        input_image, target_image, mean, std, fname, slice_num = batch\n",
    "        val_inputs = input_image.to(device)\n",
    "        val_targets = target_image.to(device)\n",
    "        std = std.to(device)\n",
    "        mean = mean.to(device)\n",
    "\n",
    "        val_outputs = model(val_inputs)\n",
    "        val_outputs = val_outputs * std + mean\n",
    "\n",
    "        # NMAE\n",
    "        l1 = l1_loss(val_outputs, val_targets) / torch.sum(torch.abs(val_targets))\n",
    "        total_l1_loss += l1.item()\n",
    "        # NMSE \n",
    "        nmse_loss = mse_fct(val_outputs, val_targets) / torch.sum(torch.abs(val_targets)**2)\n",
    "        total_nmse_loss += nmse_loss.item()\n",
    "        # PSNR\n",
    "        psnr_loss = 20*torch.log10(torch.tensor(val_targets.max().unsqueeze(0).item()))-10*torch.log10(psner_mse_fct(val_outputs,val_targets))\n",
    "        total_psnr_loss += psnr_loss.item()\n",
    "        # SSIM = 1 - loss\n",
    "        ssim_loss = ssim_fct(val_outputs, val_targets, data_range = val_targets.max().unsqueeze(0))\n",
    "        total_ssim_loss += (1-ssim_loss.item())\n",
    "\n",
    "    validation_loss_l1 = total_l1_loss / len(dataloader) \n",
    "    validation_loss_NMSE = total_nmse_loss / len(dataloader)\n",
    "    validation_loss_PSNR = total_psnr_loss / len(dataloader)\n",
    "    validation_loss_SSIM = total_ssim_loss / len(dataloader)\n",
    "\n",
    "    return validation_loss_l1, validation_loss_NMSE, validation_loss_PSNR, validation_loss_SSIM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Unet(in_chans=1, out_chans=1, chans=32, num_pool_layers=4, drop_prob=0.0)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "##########################\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, TRAINING_EPOCH/1, eta_min=0.0001, last_epoch=-1)\n",
    "lossfn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "best_loss = 10.000\n",
    "for iteration in range(TRAINING_EPOCH):\n",
    "    print('Iteration:', iteration+1)\n",
    "    # training\n",
    "    training_loss = train(model, train_dataloader, optimizer)\n",
    "    print('Training NMSE', training_loss) \n",
    "    writer.add_scalar(\"Training NMSE\", training_loss, iteration+1)\n",
    "    # val\n",
    "    validation_loss = evaluate(model, val_dataloader)\n",
    "    print('Validation NMSE', validation_loss) \n",
    "    writer.add_scalar(\"Validation NMSE\", validation_loss, iteration+1)\n",
    "    if best_loss > validation_loss:\n",
    "        best_loss = validation_loss\n",
    "        save_path = '/cheng/metaMRI/metaMRI/save/'+ experiment_name + '/' + experiment_name + '_E' + str(iteration+1) + '_best.pth'\n",
    "        torch.save((model.state_dict()), save_path)\n",
    "        print('Model saved to', save_path)\n",
    "    else:\n",
    "        pass\n",
    "    scheduler.step()\n",
    "    print('Learning rate: ', optimizer.param_groups[0]['lr'])\n",
    "### save model\n",
    "# save_path = '/cheng/metaMRI/metaMRI/save/'+ experiment_name + '/' + experiment_name + '.pth'\n",
    "# torch.save((model.state_dict()), save_path)\n",
    "# print('Model saved to', save_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
